{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T01:21:56.792514Z",
     "iopub.status.busy": "2025-10-17T01:21:56.792205Z",
     "iopub.status.idle": "2025-10-17T01:21:59.482484Z",
     "shell.execute_reply": "2025-10-17T01:21:59.480637Z"
    },
    "id": "sIWOcR5-BTLh"
   },
   "outputs": [],
   "source": [
    "# PROJET : Détection de la Pneumonie à partir de Radiographies\n",
    "# Auteur : KONE Zana , OUEDRAOGO Freddy , PITROIPA Soraya\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) Installation des dépendances\n",
    "# -------------------------------------------------------------\n",
    "!pip install -q tensorflow keras scikit-learn seaborn matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-17T01:21:59.486927Z",
     "iopub.status.busy": "2025-10-17T01:21:59.486622Z",
     "iopub.status.idle": "2025-10-17T01:22:07.338561Z",
     "shell.execute_reply": "2025-10-17T01:22:07.337471Z"
    },
    "id": "teFMwyChBdG7",
    "outputId": "bd7286e6-5f49-442a-9d59-0137c7a447da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU disponible: []\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorFlow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGPU disponible: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.config.list_physical_devices(\u001b[33m'\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mcode\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#VSC-67158eec\u001b[39;00m\n\u001b[32m     35\u001b[39m python\n",
      "\u001b[31mNameError\u001b[39m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 2) Imports\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "code\n",
    "#VSC-67158eec\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 3) Montage de Google Drive et Configuration (safe pour local)\n",
    "# -------------------------------------------------------------\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = '/content/drive/MyDrive/chest_xray/chest_xray'\n",
    "    WORK_DIR = '/content/chest_xray_reduced'\n",
    "    print('Google Colab drive mounted')\n",
    "except Exception:\n",
    "    # Not running in Colab - provide local defaults (adjust if needed)\n",
    "    print('Not running in Google Colab - using local paths if available')\n",
    "    DATA_DIR = './data/chest_xray/chest_xray'\n",
    "    WORK_DIR = './chest_xray_reduced'\n",
    "\n",
    "# Hyperparamètres (AMÉLIORÉS)\n",
    "IMG_SIZE = (224, 224)  # Taille standard pour MobileNetV2\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "EPOCHS_INITIAL = 15  # Augmenté\n",
    "EPOCHS_FINETUNE = 10  # Augmenté\n",
    "\n",
    "print(f\"Dataset source : {DATA_DIR}\")\n",
    "print(f\"Dataset réduit : {WORK_DIR}\")\n",
    "code\n",
    "#VSC-39998e89\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 4) Création d'un dataset équilibré (TAILLE AUGMENTÉE)\n",
    "# -------------------------------------------------------------\n",
    "def create_balanced_subset(src_root, dst_root, max_per_class=2000):\n",
    "    \"\"\"\n",
    "    Crée un sous-ensemble équilibré du dataset original\n",
    "    max_per_class augmenté à 2000 pour avoir plus de données\n",
    "    \"\"\"\n",
    "    if os.path.exists(dst_root):\n",
    "        shutil.rmtree(dst_root)\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    classes = ['PNEUMONIA', 'NORMAL']\n",
    "\n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            src_path = os.path.join(src_root, split, cls)\n",
    "            dst_path = os.path.join(dst_root, split, cls)\n",
    "            os.makedirs(dst_path, exist_ok=True)\n",
    "\n",
    "            all_imgs = [f for f in os.listdir(src_path) if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "            random.shuffle(all_imgs)\n",
    "            selected_imgs = all_imgs[:max_per_class]\n",
    "\n",
    "            for img in selected_imgs:\n",
    "                shutil.copy2(os.path.join(src_path, img), os.path.join(dst_path, img))\n",
    "\n",
    "            print(f\"{split}/{cls}: {len(selected_imgs)} images copiées.\")\n",
    "\n",
    "    print(f\"\\n✅ Dataset équilibré créé dans {dst_root}\")\n",
    "\n",
    "# Création du dataset\n",
    "create_balanced_subset(DATA_DIR, WORK_DIR, max_per_class=2000)\n",
    "\n",
    "code\n",
    "#VSC-cfd9c078\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 5) Préparation des générateurs d'images (AVEC AUGMENTATION)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# IMPORTANT : Augmentation de données pour le training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Pas d'augmentation pour validation et test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/test',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Classes détectées : {train_gen.class_indices}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n",
    "print(f\"Test samples: {test_gen.samples}\")\n",
    "\n",
    "code\n",
    "#VSC-27f225e2\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6) Construction du modèle CNN (MobileNetV2)\n",
    "# -------------------------------------------------------------\n",
    "def build_cnn_model():\n",
    "    \"\"\"Construction du modèle CNN avec MobileNetV2\"\"\"\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze base model initialement\n",
    "\n",
    "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.AUC(name='auc'),\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "\n",
    "    return model, base_model\n",
    "\n",
    "cnn_model, base_model = build_cnn_model()\n",
    "\n",
    "# Afficher le résumé\n",
    "print(\"\\n📊 Architecture du modèle:\")\n",
    "cnn_model.summary()\n",
    "print(f\"\\n✅ Nombre total de paramètres: {cnn_model.count_params():,}\")\n",
    "code\n",
    "#VSC-98b4c8c4\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 7) Callbacks pour l'entraînement\n",
    "# -------------------------------------------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_cnn_model.h5',\n",
    "        monitor='val_auc',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "code\n",
    "#VSC-a63e9254\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 8) Entraînement Initial (Base Model Frozen)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🚀 Phase 1: Entraînement initial (base model frozen)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_INITIAL,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "initial_training_time = time.time() - start_time\n",
    "print(f\"\\n⏱️  Temps d'entraînement Phase 1: {initial_training_time/60:.2f} minutes\")\n",
    "\n",
    "code\n",
    "#VSC-0537718d\n",
    "python\n",
    "\n",
    "code\n",
    "#VSC-1d78e80c\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9) Fine-tuning (Unfreeze les dernières couches)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🚀 Phase 2: Fine-tuning (unfreezing last layers)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Unfreeze les dernières couches de MobileNetV2\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze toutes les couches sauf les 30 dernières\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompiler avec un learning rate plus faible\n",
    "cnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.AUC(name='auc'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "print(f\"Nombre de couches entraînables: {len([l for l in cnn_model.layers if l.trainable])}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history_ft = cnn_model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_FINETUNE,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "finetune_training_time = time.time() - start_time\n",
    "total_training_time = initial_training_time + finetune_training_time\n",
    "\n",
    "print(f\"\\n⏱️  Temps d'entraînement Phase 2: {finetune_training_time/60:.2f} minutes\")\n",
    "print(f\"⏱️  TEMPS TOTAL D'ENTRAÎNEMENT: {total_training_time/60:.2f} minutes\")\n",
    "\n",
    "code\n",
    "#VSC-3989f691\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 10) Évaluation Complète du CNN\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n📊 ÉVALUATION COMPLÈTE DU MODÈLE CNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Charger le meilleur modèle\n",
    "cnn_model = keras.models.load_model('best_cnn_model.h5')\n",
    "\n",
    "# Prédictions sur test set\n",
    "test_gen.reset()\n",
    "y_pred_proba = cnn_model.predict(test_gen, verbose=1)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "y_true = test_gen.classes\n",
    "\n",
    "# Métriques globales\n",
    "test_loss, test_acc, test_auc, test_precision, test_recall = cnn_model.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# Calcul de métriques supplémentaires\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Spécificité (important en médical)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"\\n📈 RÉSULTATS SUR L'ENSEMBLE DE TEST:\")\n",
    "print(f\"  • Accuracy:    {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"  • AUC:         {test_auc:.4f}\")\n",
    "print(f\"  • Precision:   {test_precision:.4f}\")\n",
    "print(f\"  • Recall:      {test_recall:.4f}\")\n",
    "print(f\"  • F1-Score:    {f1:.4f}\")\n",
    "print(f\"  • Specificity: {specificity:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 MATRICE DE CONFUSION:\")\n",
    "print(f\"  TN={tn}, FP={fp}\")\n",
    "print(f\"  FN={fn}, TP={tp}\")\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "print(\"\\n📋 RAPPORT DE CLASSIFICATION:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n",
    "\n",
    "code\n",
    "#VSC-dab0682c\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 11) Visualisations CNN\n",
    "# -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'] + history_ft.history['accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_accuracy'] + history_ft.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Accuracy du modèle CNN')\n",
    "axes[0, 0].set_xlabel('Époques')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].axvline(x=EPOCHS_INITIAL, color='r', linestyle='--', label='Fine-tuning start')\n",
    "\n",
    "# 2. Loss\n",
    "axes[0, 1].plot(history.history['loss'] + history_ft.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'] + history_ft.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Loss du modèle CNN')\n",
    "axes[0, 1].set_xlabel('Époques')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].axvline(x=EPOCHS_INITIAL, color='r', linestyle='--')\n",
    "\n",
    "# 3. AUC\n",
    "axes[0, 2].plot(history.history['auc'] + history_ft.history['auc'], label='Train')\n",
    "axes[0, 2].plot(history.history['val_auc'] + history_ft.history['val_auc'], label='Validation')\n",
    "axes[0, 2].set_title('AUC du modèle CNN')\n",
    "axes[0, 2].set_xlabel('Époques')\n",
    "axes[0, 2].set_ylabel('AUC')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].axvline(x=EPOCHS_INITIAL, color='r', linestyle='--')\n",
    "\n",
    "# 4. Matrice de confusion\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[1, 0].set_title('Matrice de Confusion')\n",
    "axes[1, 0].set_ylabel('Vrai Label')\n",
    "axes[1, 0].set_xlabel('Prédiction')\n",
    "\n",
    "# 5. Courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc_score_val = auc(fpr, tpr)\n",
    "axes[1, 1].plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_score_val:.4f})')\n",
    "axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Hasard')\n",
    "axes[1, 1].set_title('Courbe ROC')\n",
    "axes[1, 1].set_xlabel('Taux de Faux Positifs')\n",
    "axes[1, 1].set_ylabel('Taux de Vrais Positifs')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# 6. Distribution des prédictions\n",
    "axes[1, 2].hist(y_pred_proba[y_true==0], bins=50, alpha=0.5, label='NORMAL', color='green')\n",
    "axes[1, 2].hist(y_pred_proba[y_true==1], bins=50, alpha=0.5, label='PNEUMONIA', color='red')\n",
    "axes[1, 2].axvline(x=0.5, color='black', linestyle='--', label='Seuil')\n",
    "axes[1, 2].set_title('Distribution des Probabilités Prédites')\n",
    "axes[1, 2].set_xlabel('Probabilité')\n",
    "axes[1, 2].set_ylabel('Fréquence')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_evaluation_complete.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "code\n",
    "#VSC-efc63b77\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 12) Extraction de features pour SVM & Random Forest\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🔄 EXTRACTION DE FEATURES POUR SVM ET RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def extract_features(generator):\n",
    "    \"\"\"Extrait les features du modèle CNN pour les modèles ML classiques\"\"\"\n",
    "    features, labels = [], []\n",
    "    steps = generator.samples // generator.batch_size + 1\n",
    "\n",
    "    for i, (imgs, lbls) in enumerate(generator):\n",
    "        if i >= steps:\n",
    "            break\n",
    "        feats = base_model.predict(imgs, verbose=0)\n",
    "        features.append(np.mean(feats, axis=(1,2)))\n",
    "        labels.extend(lbls)\n",
    "\n",
    "    return np.vstack(features), np.array(labels)\n",
    "\n",
    "print(\"Extraction des features d'entraînement...\")\n",
    "X_train, y_train = extract_features(train_gen)\n",
    "\n",
    "print(\"Extraction des features de validation...\")\n",
    "val_gen_for_features = train_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "X_val, y_val = extract_features(val_gen_for_features)\n",
    "\n",
    "print(\"Extraction des features de test...\")\n",
    "test_gen.reset()\n",
    "X_test, y_test = extract_features(test_gen)\n",
    "\n",
    "print(f\"\\n✅ Features extraites:\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Val:   {X_val.shape}\")\n",
    "print(f\"  Test:  {X_test.shape}\")\n",
    "\n",
    "code\n",
    "#VSC-3437c76f\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 13) SVM avec GridSearchCV (OPTIMISÉ)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🔍 ENTRAÎNEMENT SVM AVEC GRIDSEARCHCV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True, random_state=SEED)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid_svm,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "svm_training_time = time.time() - start_time\n",
    "\n",
    "best_svm = grid_svm.best_estimator_\n",
    "\n",
    "print(f\"\\n✅ Meilleurs hyperparamètres SVM:\")\n",
    "print(f\"  {grid_svm.best_params_}\")\n",
    "print(f\"⏱️  Temps d'entraînement SVM: {svm_training_time/60:.2f} minutes\")\n",
    "\n",
    "# Évaluation SVM sur test\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "y_pred_svm_proba = best_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "svm_auc = roc_auc_score(y_test, y_pred_svm_proba)\n",
    "svm_precision, svm_recall, svm_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_svm, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"\\n📈 RÉSULTATS SVM SUR TEST:\")\n",
    "print(f\"  • Accuracy:  {svm_acc:.4f}\")\n",
    "print(f\"  • AUC:       {svm_auc:.4f}\")\n",
    "print(f\"  • Precision: {svm_precision:.4f}\")\n",
    "print(f\"  • Recall:    {svm_recall:.4f}\")\n",
    "print(f\"  • F1-Score:  {svm_f1:.4f}\")\n",
    "\n",
    "code\n",
    "#VSC-85f6e060\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 14) Random Forest avec GridSearchCV (OPTIMISÉ)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🌲 ENTRAÎNEMENT RANDOM FOREST AVEC GRIDSEARCHCV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid_rf,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_training_time = time.time() - start_time\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "print(f\"\\n✅ Meilleurs hyperparamètres Random Forest:\")\n",
    "print(f\"  {grid_rf.best_params_}\")\n",
    "print(f\"⏱️  Temps d'entraînement RF: {rf_training_time/60:.2f} minutes\")\n",
    "\n",
    "# Évaluation RF sur test\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_rf_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rf_auc = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "rf_precision, rf_recall, rf_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_rf, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"\\n📈 RÉSULTATS RANDOM FOREST SUR TEST:\")\n",
    "print(f\"  • Accuracy:  {rf_acc:.4f}\")\n",
    "print(f\"  • AUC:       {rf_auc:.4f}\")\n",
    "print(f\"  • Precision: {rf_precision:.4f}\")\n",
    "print(f\"  • Recall:    {rf_recall:.4f}\")\n",
    "print(f\"  • F1-Score:  {rf_f1:.4f}\")\n",
    "\n",
    "code\n",
    "#VSC-49d4f94f\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15) COMPARAISON FINALE DES MODÈLES (CORRIGÉE)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🏆 COMPARAISON FINALE DES MODÈLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Créer DataFrame de comparaison\n",
    "results_df = pd.DataFrame({\n",
    "    'Modèle': ['CNN (MobileNetV2)', 'SVM', 'Random Forest'],\n",
    "    'Accuracy': [test_acc, svm_acc, rf_acc],\n",
    "    'AUC': [test_auc, svm_auc, rf_auc],\n",
    "    'Precision': [test_precision, svm_precision, rf_precision],\n",
    "    'Recall': [test_recall, svm_recall, rf_recall],\n",
    "    'F1-Score': [f1, svm_f1, rf_f1],\n",
    "    'Temps (min)': [\n",
    "        total_training_time/60,\n",
    "        svm_training_time/60,\n",
    "        rf_training_time/60\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identifier le meilleur modèle\n",
    "best_model_idx = results_df['AUC'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Modèle']\n",
    "\n",
    "print(f\"\\n🥇 MEILLEUR MODÈLE: {best_model_name}\")\n",
    "print(f\"   AUC: {results_df.loc[best_model_idx, 'AUC']:.4f}\")\n",
    "\n",
    "code\n",
    "#VSC-c641b9f1\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 16) Visualisation Comparative Finale\n",
    "# -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Graphique 1: Comparaison des Accuracy\n",
    "axes[0, 0].bar(results_df['Modèle'], results_df['Accuracy'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0, 0].set_title('Comparaison des Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_ylim([0.5, 1.0])\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Graphique 2: Comparaison des AUC\n",
    "axes[0, 1].bar(results_df['Modèle'], results_df['AUC'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0, 1].set_title('Comparaison des AUC', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('AUC')\n",
    "axes[0, 1].set_ylim([0.5, 1.0])\n",
    "for i, v in enumerate(results_df['AUC']):\n",
    "    axes[0, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Graphique 3: Temps d'entraînement\n",
    "axes[1, 0].bar(results_df['Modèle'], results_df['Temps (min)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[1, 0].set_title('Temps d\\'entraînement', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Minutes')\n",
    "for i, v in enumerate(results_df['Temps (min)']):\n",
    "    axes[1, 0].text(i, v + 0.5, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Graphique 4: Comparaison Precision/Recall/F1\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "\n",
    "axes[1, 1].bar(x - width, results_df['Precision'], width, label='Precision', color='#3498db')\n",
    "axes[1, 1].bar(x, results_df['Recall'], width, label='Recall', color='#e74c3c')\n",
    "axes[1, 1].bar(x + width, results_df['F1-Score'], width, label='F1-Score', color='#2ecc71')\n",
    "axes[1, 1].set_title('Comparaison Precision/Recall/F1', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(results_df['Modèle'], rotation=15, ha='right')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_ylim([0.5, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparaison_finale_modeles.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "code\n",
    "#VSC-39cfbe35\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 17) Comparaison des Matrices de Confusion\n",
    "# -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# CNN\n",
    "cm_cnn = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[0].set_title(f'CNN (Acc: {test_acc:.3f})', fontweight='bold')\n",
    "axes[0].set_ylabel('Vrai Label')\n",
    "axes[0].set_xlabel('Prédiction')\n",
    "\n",
    "# SVM\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[1].set_title(f'SVM (Acc: {svm_acc:.3f})', fontweight='bold')\n",
    "axes[1].set_ylabel('Vrai Label')\n",
    "axes[1].set_xlabel('Prédiction')\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[2],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[2].set_title(f'Random Forest (Acc: {rf_acc:.3f})', fontweight='bold')\n",
    "axes[2].set_ylabel('Vrai Label')\n",
    "axes[2].set_xlabel('Prédiction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('matrices_confusion_comparaison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "code\n",
    "#VSC-0cb772f4\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 18) Courbes ROC Comparatives\n",
    "# -------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# CNN\n",
    "fpr_cnn, tpr_cnn, _ = roc_curve(y_true, y_pred_proba)\n",
    "plt.plot(fpr_cnn, tpr_cnn, label=f'CNN (AUC = {test_auc:.4f})', linewidth=2)\n",
    "\n",
    "# SVM\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_svm_proba)\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {svm_auc:.4f})', linewidth=2)\n",
    "\n",
    "# Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf_proba)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.4f})', linewidth=2)\n",
    "\n",
    "# Ligne de hasard\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Hasard (AUC = 0.5)', linewidth=1)\n",
    "\n",
    "plt.xlabel('Taux de Faux Positifs', fontsize=12)\n",
    "plt.ylabel('Taux de Vrais Positifs', fontsize=12)\n",
    "plt.title('Courbes ROC Comparatives des Trois Modèles', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('courbes_roc_comparaison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "code\n",
    "#VSC-d989735b\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 19) Sauvegarde des Modèles\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n💾 SAUVEGARDE DES MODÈLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sauvegarder le meilleur modèle CNN\n",
    "cnn_model.save('best_cnn_model_final.h5')\n",
    "print(\"✅ Modèle CNN sauvegardé: best_cnn_model_final.h5\")\n",
    "\n",
    "# Sauvegarder SVM et RF avec joblib\n",
    "import joblib\n",
    "joblib.dump(best_svm, 'best_svm_model.pkl')\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n",
    "print(\"✅ Modèle SVM sauvegardé: best_svm_model.pkl\")\n",
    "print(\"✅ Modèle RF sauvegardé: best_rf_model.pkl\")\n",
    "\n",
    "# Sauvegarder les résultats\n",
    "results_df.to_csv('resultats_comparaison_modeles.csv', index=False)\n",
    "print(\"✅ Résultats sauvegardés: resultats_comparaison_modeles.csv\")\n",
    "\n",
    "code\n",
    "#VSC-35f0bb4c\n",
    "python\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Téléchargement des fichiers...\")\n",
    "\n",
    "try:\n",
    "    files.download('best_cnn_model_final.h5')\n",
    "    files.download('best_svm_model.pkl')\n",
    "    files.download('best_rf_model.pkl')\n",
    "    files.download('resultats_comparaison_modeles.csv')\n",
    "    print(\"\\n✅ Fichiers prêts à être téléchargés.\")\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur est survenue lors du téléchargement : {e}\")\n",
    "\n",
    "print(\"\\nUne fois les fichiers téléchargés, vous pourrez les utiliser dans votre environnement local pour votre application Streamlit.\")\n",
    "code\n",
    "#VSC-68cca564\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 20) Analyse des Erreurs du Meilleur Modèle\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n🔍 ANALYSE DES ERREURS DU MEILLEUR MODÈLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Utiliser le modèle CNN (généralement le meilleur)\n",
    "test_gen.reset()\n",
    "\n",
    "# Récupérer les noms de fichiers\n",
    "filenames = test_gen.filenames\n",
    "y_true_labels = ['PNEUMONIA' if y == 1 else 'NORMAL' for y in y_true]\n",
    "y_pred_labels = ['PNEUMONIA' if y == 1 else 'NORMAL' for y in y_pred]\n",
    "\n",
    "# Identifier les erreurs\n",
    "errors_idx = np.where(y_true != y_pred)[0]\n",
    "print(f\"Nombre total d'erreurs: {len(errors_idx)} / {len(y_true)} ({len(errors_idx)/len(y_true)*100:.2f}%)\")\n",
    "\n",
    "# Faux Positifs (prédit PNEUMONIA alors que NORMAL)\n",
    "fp_idx = np.where((y_true == 0) & (y_pred == 1))[0]\n",
    "print(f\"Faux Positifs: {len(fp_idx)}\")\n",
    "\n",
    "# Faux Négatifs (prédit NORMAL alors que PNEUMONIA)\n",
    "fn_idx = np.where((y_true == 1) & (y_pred == 0))[0]\n",
    "print(f\"Faux Négatifs: {len(fn_idx)}\")\n",
    "\n",
    "# Créer un DataFrame des erreurs\n",
    "errors_df = pd.DataFrame({\n",
    "    'Fichier': [filenames[i] for i in errors_idx],\n",
    "    'Vrai_Label': [y_true_labels[i] for i in errors_idx],\n",
    "    'Pred_Label': [y_pred_labels[i] for i in errors_idx],\n",
    "    'Confiance': [y_pred_proba[i][0] for i in errors_idx]\n",
    "})\n",
    "\n",
    "print(\"\\n📋 Exemples d'erreurs:\")\n",
    "print(errors_df.head(10))\n",
    "\n",
    "# Visualiser quelques erreurs\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(errors_idx[:10]):\n",
    "    img_path = os.path.join(WORK_DIR, 'test', filenames[idx])\n",
    "    img = plt.imread(img_path)\n",
    "\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(\n",
    "        f\"Vrai: {y_true_labels[idx]}\\n\"\n",
    "        f\"Pred: {y_pred_labels[idx]}\\n\"\n",
    "        f\"Conf: {y_pred_proba[idx][0]:.2f}\",\n",
    "        fontsize=10,\n",
    "        color='red'\n",
    "    )\n",
    "\n",
    "plt.suptitle('Exemples d\\'Erreurs de Classification', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analyse_erreurs.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "code\n",
    "#VSC-aa166b85\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 21) Résumé Final pour le Rapport\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 20 + \"📊 RÉSUMÉ FINAL DU PROJET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n🎯 OBJECTIF: Détection de Pneumonie par Radiographie Thoracique\")\n",
    "print(f\"\\n📁 DONNÉES:\")\n",
    "print(f\"  • Dataset: Chest X-Ray Images (Pneumonia)\")\n",
    "print(f\"  • Training samples: {train_gen.samples}\")\n",
    "print(f\"  • Validation samples: {val_gen.samples}\")\n",
    "print(f\"  • Test samples: {test_gen.samples}\")\n",
    "print(f\"  • Classes: NORMAL (0), PNEUMONIA (1)\")\n",
    "\n",
    "print(f\"\\n🤖 MODÈLES COMPARÉS:\")\n",
    "print(f\"  1. CNN avec Transfer Learning (MobileNetV2)\")\n",
    "print(f\"     - Paramètres totaux: {cnn_model.count_params():,}\")\n",
    "print(f\"     - Temps d'entraînement: {total_training_time/60:.2f} min\")\n",
    "print(f\"  2. SVM avec features CNN\")\n",
    "print(f\"     - Temps d'entraînement: {svm_training_time/60:.2f} min\")\n",
    "print(f\"  3. Random Forest avec features CNN\")\n",
    "print(f\"     - Temps d'entraînement: {rf_training_time/60:.2f} min\")\n",
    "\n",
    "print(f\"\\n🏆 MEILLEUR MODÈLE: {best_model_name}\")\n",
    "print(f\"\\n📈 PERFORMANCES DU MEILLEUR MODÈLE (Test Set):\")\n",
    "best_idx = results_df['AUC'].idxmax()\n",
    "print(f\"  • Accuracy:    {results_df.loc[best_idx, 'Accuracy']:.4f} ({results_df.loc[best_idx, 'Accuracy']*100:.2f}%)\")\n",
    "print(f\"  • AUC:         {results_df.loc[best_idx, 'AUC']:.4f}\")\n",
    "print(f\"  • Precision:   {results_df.loc[best_idx, 'Precision']:.4f}\")\n",
    "print(f\"  • Recall:      {results_df.loc[best_idx, 'Recall']:.4f}\")\n",
    "print(f\"  • F1-Score:    {results_df.loc[best_idx, 'F1-Score']:.4f}\")\n",
    "\n",
    "print(f\"\\n⚠️  ANALYSE CLINIQUE:\")\n",
    "print(f\"  • Faux Positifs: {len(fp_idx)} (patients sains diagnostiqués malades)\")\n",
    "print(f\"  • Faux Négatifs: {len(fn_idx)} (patients malades non détectés)\")\n",
    "print(f\"  • Note: En contexte médical, minimiser les Faux Négatifs est CRITIQUE\")\n",
    "\n",
    "print(f\"\\n💡 RECOMMANDATIONS:\")\n",
    "print(f\"  • Le modèle peut servir d'outil d'aide au diagnostic\")\n",
    "print(f\"  • Validation médicale obligatoire avant décision clinique\")\n",
    "print(f\"  • Surveillance continue des performances en production\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Projet complété le {datetime.now().strftime('%Y-%m-%d à %H:%M:%S')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "code\n",
    "#VSC-d90555e5\n",
    "python\n",
    "\n",
    "code\n",
    "#VSC-3985f08e\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# Export explicite des DataFrames importants vers CSV\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "out_dir = 'notebook_outputs/tables'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "# Noms explicites si présents\n",
    "to_save = {}\n",
    "if 'results_df' in globals():\n",
    "    to_save['results_df'] = results_df\n",
    "if 'errors_df' in globals():\n",
    "    to_save['errors_df'] = errors_df\n",
    "# Chercher toutes les DataFrame pandas dans l'espace global\n",
    "for name, val in list(globals().items()):\n",
    "    try:\n",
    "        if isinstance(val, pd.DataFrame) and name not in to_save:\n",
    "            to_save[name] = val\n",
    "    except Exception:\n",
    "        pass\n",
    "# Sauvegarder\n",
    "for n, df in to_save.items():\n",
    "    path = os.path.join(out_dir, f'{n}.csv')\n",
    "    try:\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f'Saved {path}')\n",
    "    except Exception as e:\n",
    "        print(f'Could not save {n}: {e}')\n",
    "print('Export terminé')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
