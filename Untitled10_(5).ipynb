{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T01:21:56.792514Z",
     "iopub.status.busy": "2025-10-17T01:21:56.792205Z",
     "iopub.status.idle": "2025-10-17T01:21:59.482484Z",
     "shell.execute_reply": "2025-10-17T01:21:59.480637Z"
    },
    "id": "sIWOcR5-BTLh"
   },
   "outputs": [],
   "source": [
    "# PROJET : D√©tection de la Pneumonie √† partir de Radiographies\n",
    "# Auteur : KONE Zana , OUEDRAOGO Freddy , PITROIPA Soraya\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) Installation des d√©pendances\n",
    "# -------------------------------------------------------------\n",
    "!pip install -q tensorflow keras scikit-learn seaborn matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-17T01:21:59.486927Z",
     "iopub.status.busy": "2025-10-17T01:21:59.486622Z",
     "iopub.status.idle": "2025-10-17T01:22:07.338561Z",
     "shell.execute_reply": "2025-10-17T01:22:07.337471Z"
    },
    "id": "teFMwyChBdG7",
    "outputId": "bd7286e6-5f49-442a-9d59-0137c7a447da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU disponible: []\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorFlow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGPU disponible: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.config.list_physical_devices(\u001b[33m'\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mcode\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#VSC-67158eec\u001b[39;00m\n\u001b[32m     35\u001b[39m python\n",
      "\u001b[31mNameError\u001b[39m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 2) Imports\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "code\n",
    "#VSC-67158eec\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 3) Montage de Google Drive et Configuration (safe pour local)\n",
    "# -------------------------------------------------------------\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = '/content/drive/MyDrive/chest_xray/chest_xray'\n",
    "    WORK_DIR = '/content/chest_xray_reduced'\n",
    "    print('Google Colab drive mounted')\n",
    "except Exception:\n",
    "    # Not running in Colab - provide local defaults (adjust if needed)\n",
    "    print('Not running in Google Colab - using local paths if available')\n",
    "    DATA_DIR = './data/chest_xray/chest_xray'\n",
    "    WORK_DIR = './chest_xray_reduced'\n",
    "\n",
    "# Hyperparam√®tres (AM√âLIOR√âS)\n",
    "IMG_SIZE = (224, 224)  # Taille standard pour MobileNetV2\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "EPOCHS_INITIAL = 15  # Augment√©\n",
    "EPOCHS_FINETUNE = 10  # Augment√©\n",
    "\n",
    "print(f\"Dataset source : {DATA_DIR}\")\n",
    "print(f\"Dataset r√©duit : {WORK_DIR}\")\n",
    "code\n",
    "#VSC-39998e89\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 4) Cr√©ation d'un dataset √©quilibr√© (TAILLE AUGMENT√âE)\n",
    "# -------------------------------------------------------------\n",
    "def create_balanced_subset(src_root, dst_root, max_per_class=2000):\n",
    "    \"\"\"\n",
    "    Cr√©e un sous-ensemble √©quilibr√© du dataset original\n",
    "    max_per_class augment√© √† 2000 pour avoir plus de donn√©es\n",
    "    \"\"\"\n",
    "    if os.path.exists(dst_root):\n",
    "        shutil.rmtree(dst_root)\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "    classes = ['PNEUMONIA', 'NORMAL']\n",
    "\n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            src_path = os.path.join(src_root, split, cls)\n",
    "            dst_path = os.path.join(dst_root, split, cls)\n",
    "            os.makedirs(dst_path, exist_ok=True)\n",
    "\n",
    "            all_imgs = [f for f in os.listdir(src_path) if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "            random.shuffle(all_imgs)\n",
    "            selected_imgs = all_imgs[:max_per_class]\n",
    "\n",
    "            for img in selected_imgs:\n",
    "                shutil.copy2(os.path.join(src_path, img), os.path.join(dst_path, img))\n",
    "\n",
    "            print(f\"{split}/{cls}: {len(selected_imgs)} images copi√©es.\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Dataset √©quilibr√© cr√©√© dans {dst_root}\")\n",
    "\n",
    "# Cr√©ation du dataset\n",
    "create_balanced_subset(DATA_DIR, WORK_DIR, max_per_class=2000)\n",
    "\n",
    "code\n",
    "#VSC-cfd9c078\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 5) Pr√©paration des g√©n√©rateurs d'images (AVEC AUGMENTATION)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# IMPORTANT : Augmentation de donn√©es pour le training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Pas d'augmentation pour validation et test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/test',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Classes d√©tect√©es : {train_gen.class_indices}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n",
    "print(f\"Test samples: {test_gen.samples}\")\n",
    "\n",
    "code\n",
    "#VSC-27f225e2\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6) Construction du mod√®le CNN (MobileNetV2)\n",
    "# -------------------------------------------------------------\n",
    "def build_cnn_model():\n",
    "    \"\"\"Construction du mod√®le CNN avec MobileNetV2\"\"\"\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze base model initialement\n",
    "\n",
    "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.AUC(name='auc'),\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "\n",
    "    return model, base_model\n",
    "\n",
    "cnn_model, base_model = build_cnn_model()\n",
    "\n",
    "# Afficher le r√©sum√©\n",
    "print(\"\\nüìä Architecture du mod√®le:\")\n",
    "cnn_model.summary()\n",
    "print(f\"\\n‚úÖ Nombre total de param√®tres: {cnn_model.count_params():,}\")\n",
    "code\n",
    "#VSC-98b4c8c4\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 7) Callbacks pour l'entra√Ænement\n",
    "# -------------------------------------------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_cnn_model.h5',\n",
    "        monitor='val_auc',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "code\n",
    "#VSC-a63e9254\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 8) Entra√Ænement Initial (Base Model Frozen)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüöÄ Phase 1: Entra√Ænement initial (base model frozen)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_INITIAL,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "initial_training_time = time.time() - start_time\n",
    "print(f\"\\n‚è±Ô∏è  Temps d'entra√Ænement Phase 1: {initial_training_time/60:.2f} minutes\")\n",
    "\n",
    "code\n",
    "#VSC-0537718d\n",
    "python\n",
    "\n",
    "code\n",
    "#VSC-1d78e80c\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9) Fine-tuning (Unfreeze les derni√®res couches)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüöÄ Phase 2: Fine-tuning (unfreezing last layers)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Unfreeze les derni√®res couches de MobileNetV2\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze toutes les couches sauf les 30 derni√®res\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompiler avec un learning rate plus faible\n",
    "cnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.AUC(name='auc'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "print(f\"Nombre de couches entra√Ænables: {len([l for l in cnn_model.layers if l.trainable])}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history_ft = cnn_model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_FINETUNE,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "finetune_training_time = time.time() - start_time\n",
    "total_training_time = initial_training_time + finetune_training_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Temps d'entra√Ænement Phase 2: {finetune_training_time/60:.2f} minutes\")\n",
    "print(f\"‚è±Ô∏è  TEMPS TOTAL D'ENTRA√éNEMENT: {total_training_time/60:.2f} minutes\")\n",
    "\n",
    "code\n",
    "#VSC-3989f691\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 10) √âvaluation Compl√®te du CNN\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüìä √âVALUATION COMPL√àTE DU MOD√àLE CNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Charger le meilleur mod√®le\n",
    "cnn_model = keras.models.load_model('best_cnn_model.h5')\n",
    "\n",
    "# Pr√©dictions sur test set\n",
    "test_gen.reset()\n",
    "y_pred_proba = cnn_model.predict(test_gen, verbose=1)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "y_true = test_gen.classes\n",
    "\n",
    "# M√©triques globales\n",
    "test_loss, test_acc, test_auc, test_precision, test_recall = cnn_model.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# Calcul de m√©triques suppl√©mentaires\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Sp√©cificit√© (important en m√©dical)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(f\"\\nüìà R√âSULTATS SUR L'ENSEMBLE DE TEST:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:    {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ AUC:         {test_auc:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision:   {test_precision:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:      {test_recall:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score:    {f1:.4f}\")\n",
    "print(f\"  ‚Ä¢ Specificity: {specificity:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä MATRICE DE CONFUSION:\")\n",
    "print(f\"  TN={tn}, FP={fp}\")\n",
    "print(f\"  FN={fn}, TP={tp}\")\n",
    "\n",
    "# Rapport de classification d√©taill√©\n",
    "print(\"\\nüìã RAPPORT DE CLASSIFICATION:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n",
    "\n",
    "code\n",
    "#VSC-dab0682c\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 11) Visualisations CNN\n",
    "# -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'] + history_ft.history['accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_accuracy'] + history_ft.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Accuracy du mod√®le CNN')\n",
    "axes[0, 0].set_xlabel('√âpoques')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].axvline(x=EPOCHS_INITIAL, color='r', linestyle='--', label='Fine-tuning start')\n",
    "\n",
    "# 2. Loss\n",
    "axes[0, 1].plot(history.history['loss'] + history_ft.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'] + history_ft.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Loss du mod√®le CNN')\n",
    "axes[0, 1].set_xlabel('√âpoques')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].axvline(x=EPOCHS_INITIAL, color='r', linestyle='--')\n",
    "\n",
    "# 3. AUC\n",
    "axes[0, 2].plot(history.history['auc'] + history_ft.history['auc'], label='Train')\n",
    "axes[0, 2].plot(history.history['val_auc'] + history_ft.history['val_auc'], label='Validation')\n",
    "axes[0, 2].set_title('AUC du mod√®le CNN')\n",
    "axes[0, 2].set_xlabel('√âpoques')\n",
    "axes[0, 2].set_ylabel('AUC')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].axvline(x=EPOCHS_INITIAL, color='r', linestyle='--')\n",
    "\n",
    "# 4. Matrice de confusion\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[1, 0].set_title('Matrice de Confusion')\n",
    "axes[1, 0].set_ylabel('Vrai Label')\n",
    "axes[1, 0].set_xlabel('Pr√©diction')\n",
    "\n",
    "# 5. Courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc_score_val = auc(fpr, tpr)\n",
    "axes[1, 1].plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_score_val:.4f})')\n",
    "axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Hasard')\n",
    "axes[1, 1].set_title('Courbe ROC')\n",
    "axes[1, 1].set_xlabel('Taux de Faux Positifs')\n",
    "axes[1, 1].set_ylabel('Taux de Vrais Positifs')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# 6. Distribution des pr√©dictions\n",
    "axes[1, 2].hist(y_pred_proba[y_true==0], bins=50, alpha=0.5, label='NORMAL', color='green')\n",
    "axes[1, 2].hist(y_pred_proba[y_true==1], bins=50, alpha=0.5, label='PNEUMONIA', color='red')\n",
    "axes[1, 2].axvline(x=0.5, color='black', linestyle='--', label='Seuil')\n",
    "axes[1, 2].set_title('Distribution des Probabilit√©s Pr√©dites')\n",
    "axes[1, 2].set_xlabel('Probabilit√©')\n",
    "axes[1, 2].set_ylabel('Fr√©quence')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_evaluation_complete.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "code\n",
    "#VSC-efc63b77\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 12) Extraction de features pour SVM & Random Forest\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüîÑ EXTRACTION DE FEATURES POUR SVM ET RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def extract_features(generator):\n",
    "    \"\"\"Extrait les features du mod√®le CNN pour les mod√®les ML classiques\"\"\"\n",
    "    features, labels = [], []\n",
    "    steps = generator.samples // generator.batch_size + 1\n",
    "\n",
    "    for i, (imgs, lbls) in enumerate(generator):\n",
    "        if i >= steps:\n",
    "            break\n",
    "        feats = base_model.predict(imgs, verbose=0)\n",
    "        features.append(np.mean(feats, axis=(1,2)))\n",
    "        labels.extend(lbls)\n",
    "\n",
    "    return np.vstack(features), np.array(labels)\n",
    "\n",
    "print(\"Extraction des features d'entra√Ænement...\")\n",
    "X_train, y_train = extract_features(train_gen)\n",
    "\n",
    "print(\"Extraction des features de validation...\")\n",
    "val_gen_for_features = train_datagen.flow_from_directory(\n",
    "    WORK_DIR + '/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "X_val, y_val = extract_features(val_gen_for_features)\n",
    "\n",
    "print(\"Extraction des features de test...\")\n",
    "test_gen.reset()\n",
    "X_test, y_test = extract_features(test_gen)\n",
    "\n",
    "print(f\"\\n‚úÖ Features extraites:\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Val:   {X_val.shape}\")\n",
    "print(f\"  Test:  {X_test.shape}\")\n",
    "\n",
    "code\n",
    "#VSC-3437c76f\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 13) SVM avec GridSearchCV (OPTIMIS√â)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüîç ENTRA√éNEMENT SVM AVEC GRIDSEARCHCV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True, random_state=SEED)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid_svm,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "svm_training_time = time.time() - start_time\n",
    "\n",
    "best_svm = grid_svm.best_estimator_\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleurs hyperparam√®tres SVM:\")\n",
    "print(f\"  {grid_svm.best_params_}\")\n",
    "print(f\"‚è±Ô∏è  Temps d'entra√Ænement SVM: {svm_training_time/60:.2f} minutes\")\n",
    "\n",
    "# √âvaluation SVM sur test\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "y_pred_svm_proba = best_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "svm_auc = roc_auc_score(y_test, y_pred_svm_proba)\n",
    "svm_precision, svm_recall, svm_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_svm, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà R√âSULTATS SVM SUR TEST:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:  {svm_acc:.4f}\")\n",
    "print(f\"  ‚Ä¢ AUC:       {svm_auc:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {svm_precision:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:    {svm_recall:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score:  {svm_f1:.4f}\")\n",
    "\n",
    "code\n",
    "#VSC-85f6e060\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 14) Random Forest avec GridSearchCV (OPTIMIS√â)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüå≤ ENTRA√éNEMENT RANDOM FOREST AVEC GRIDSEARCHCV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid_rf,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_training_time = time.time() - start_time\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleurs hyperparam√®tres Random Forest:\")\n",
    "print(f\"  {grid_rf.best_params_}\")\n",
    "print(f\"‚è±Ô∏è  Temps d'entra√Ænement RF: {rf_training_time/60:.2f} minutes\")\n",
    "\n",
    "# √âvaluation RF sur test\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_rf_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rf_auc = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "rf_precision, rf_recall, rf_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_rf, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà R√âSULTATS RANDOM FOREST SUR TEST:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:  {rf_acc:.4f}\")\n",
    "print(f\"  ‚Ä¢ AUC:       {rf_auc:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {rf_precision:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:    {rf_recall:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score:  {rf_f1:.4f}\")\n",
    "\n",
    "code\n",
    "#VSC-49d4f94f\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15) COMPARAISON FINALE DES MOD√àLES (CORRIG√âE)\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüèÜ COMPARAISON FINALE DES MOD√àLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cr√©er DataFrame de comparaison\n",
    "results_df = pd.DataFrame({\n",
    "    'Mod√®le': ['CNN (MobileNetV2)', 'SVM', 'Random Forest'],\n",
    "    'Accuracy': [test_acc, svm_acc, rf_acc],\n",
    "    'AUC': [test_auc, svm_auc, rf_auc],\n",
    "    'Precision': [test_precision, svm_precision, rf_precision],\n",
    "    'Recall': [test_recall, svm_recall, rf_recall],\n",
    "    'F1-Score': [f1, svm_f1, rf_f1],\n",
    "    'Temps (min)': [\n",
    "        total_training_time/60,\n",
    "        svm_training_time/60,\n",
    "        rf_training_time/60\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identifier le meilleur mod√®le\n",
    "best_model_idx = results_df['AUC'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Mod√®le']\n",
    "\n",
    "print(f\"\\nü•á MEILLEUR MOD√àLE: {best_model_name}\")\n",
    "print(f\"   AUC: {results_df.loc[best_model_idx, 'AUC']:.4f}\")\n",
    "\n",
    "code\n",
    "#VSC-c641b9f1\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 16) Visualisation Comparative Finale\n",
    "# -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Graphique 1: Comparaison des Accuracy\n",
    "axes[0, 0].bar(results_df['Mod√®le'], results_df['Accuracy'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0, 0].set_title('Comparaison des Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_ylim([0.5, 1.0])\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Graphique 2: Comparaison des AUC\n",
    "axes[0, 1].bar(results_df['Mod√®le'], results_df['AUC'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0, 1].set_title('Comparaison des AUC', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('AUC')\n",
    "axes[0, 1].set_ylim([0.5, 1.0])\n",
    "for i, v in enumerate(results_df['AUC']):\n",
    "    axes[0, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Graphique 3: Temps d'entra√Ænement\n",
    "axes[1, 0].bar(results_df['Mod√®le'], results_df['Temps (min)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[1, 0].set_title('Temps d\\'entra√Ænement', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Minutes')\n",
    "for i, v in enumerate(results_df['Temps (min)']):\n",
    "    axes[1, 0].text(i, v + 0.5, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Graphique 4: Comparaison Precision/Recall/F1\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "\n",
    "axes[1, 1].bar(x - width, results_df['Precision'], width, label='Precision', color='#3498db')\n",
    "axes[1, 1].bar(x, results_df['Recall'], width, label='Recall', color='#e74c3c')\n",
    "axes[1, 1].bar(x + width, results_df['F1-Score'], width, label='F1-Score', color='#2ecc71')\n",
    "axes[1, 1].set_title('Comparaison Precision/Recall/F1', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(results_df['Mod√®le'], rotation=15, ha='right')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_ylim([0.5, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparaison_finale_modeles.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "code\n",
    "#VSC-39cfbe35\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 17) Comparaison des Matrices de Confusion\n",
    "# -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# CNN\n",
    "cm_cnn = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[0].set_title(f'CNN (Acc: {test_acc:.3f})', fontweight='bold')\n",
    "axes[0].set_ylabel('Vrai Label')\n",
    "axes[0].set_xlabel('Pr√©diction')\n",
    "\n",
    "# SVM\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[1].set_title(f'SVM (Acc: {svm_acc:.3f})', fontweight='bold')\n",
    "axes[1].set_ylabel('Vrai Label')\n",
    "axes[1].set_xlabel('Pr√©diction')\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[2],\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "axes[2].set_title(f'Random Forest (Acc: {rf_acc:.3f})', fontweight='bold')\n",
    "axes[2].set_ylabel('Vrai Label')\n",
    "axes[2].set_xlabel('Pr√©diction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('matrices_confusion_comparaison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "code\n",
    "#VSC-0cb772f4\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 18) Courbes ROC Comparatives\n",
    "# -------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# CNN\n",
    "fpr_cnn, tpr_cnn, _ = roc_curve(y_true, y_pred_proba)\n",
    "plt.plot(fpr_cnn, tpr_cnn, label=f'CNN (AUC = {test_auc:.4f})', linewidth=2)\n",
    "\n",
    "# SVM\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_svm_proba)\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {svm_auc:.4f})', linewidth=2)\n",
    "\n",
    "# Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf_proba)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.4f})', linewidth=2)\n",
    "\n",
    "# Ligne de hasard\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Hasard (AUC = 0.5)', linewidth=1)\n",
    "\n",
    "plt.xlabel('Taux de Faux Positifs', fontsize=12)\n",
    "plt.ylabel('Taux de Vrais Positifs', fontsize=12)\n",
    "plt.title('Courbes ROC Comparatives des Trois Mod√®les', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('courbes_roc_comparaison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "code\n",
    "#VSC-d989735b\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 19) Sauvegarde des Mod√®les\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüíæ SAUVEGARDE DES MOD√àLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sauvegarder le meilleur mod√®le CNN\n",
    "cnn_model.save('best_cnn_model_final.h5')\n",
    "print(\"‚úÖ Mod√®le CNN sauvegard√©: best_cnn_model_final.h5\")\n",
    "\n",
    "# Sauvegarder SVM et RF avec joblib\n",
    "import joblib\n",
    "joblib.dump(best_svm, 'best_svm_model.pkl')\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n",
    "print(\"‚úÖ Mod√®le SVM sauvegard√©: best_svm_model.pkl\")\n",
    "print(\"‚úÖ Mod√®le RF sauvegard√©: best_rf_model.pkl\")\n",
    "\n",
    "# Sauvegarder les r√©sultats\n",
    "results_df.to_csv('resultats_comparaison_modeles.csv', index=False)\n",
    "print(\"‚úÖ R√©sultats sauvegard√©s: resultats_comparaison_modeles.csv\")\n",
    "\n",
    "code\n",
    "#VSC-35f0bb4c\n",
    "python\n",
    "from google.colab import files\n",
    "\n",
    "print(\"T√©l√©chargement des fichiers...\")\n",
    "\n",
    "try:\n",
    "    files.download('best_cnn_model_final.h5')\n",
    "    files.download('best_svm_model.pkl')\n",
    "    files.download('best_rf_model.pkl')\n",
    "    files.download('resultats_comparaison_modeles.csv')\n",
    "    print(\"\\n‚úÖ Fichiers pr√™ts √† √™tre t√©l√©charg√©s.\")\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur est survenue lors du t√©l√©chargement : {e}\")\n",
    "\n",
    "print(\"\\nUne fois les fichiers t√©l√©charg√©s, vous pourrez les utiliser dans votre environnement local pour votre application Streamlit.\")\n",
    "code\n",
    "#VSC-68cca564\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# 20) Analyse des Erreurs du Meilleur Mod√®le\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüîç ANALYSE DES ERREURS DU MEILLEUR MOD√àLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Utiliser le mod√®le CNN (g√©n√©ralement le meilleur)\n",
    "test_gen.reset()\n",
    "\n",
    "# R√©cup√©rer les noms de fichiers\n",
    "filenames = test_gen.filenames\n",
    "y_true_labels = ['PNEUMONIA' if y == 1 else 'NORMAL' for y in y_true]\n",
    "y_pred_labels = ['PNEUMONIA' if y == 1 else 'NORMAL' for y in y_pred]\n",
    "\n",
    "# Identifier les erreurs\n",
    "errors_idx = np.where(y_true != y_pred)[0]\n",
    "print(f\"Nombre total d'erreurs: {len(errors_idx)} / {len(y_true)} ({len(errors_idx)/len(y_true)*100:.2f}%)\")\n",
    "\n",
    "# Faux Positifs (pr√©dit PNEUMONIA alors que NORMAL)\n",
    "fp_idx = np.where((y_true == 0) & (y_pred == 1))[0]\n",
    "print(f\"Faux Positifs: {len(fp_idx)}\")\n",
    "\n",
    "# Faux N√©gatifs (pr√©dit NORMAL alors que PNEUMONIA)\n",
    "fn_idx = np.where((y_true == 1) & (y_pred == 0))[0]\n",
    "print(f\"Faux N√©gatifs: {len(fn_idx)}\")\n",
    "\n",
    "# Cr√©er un DataFrame des erreurs\n",
    "errors_df = pd.DataFrame({\n",
    "    'Fichier': [filenames[i] for i in errors_idx],\n",
    "    'Vrai_Label': [y_true_labels[i] for i in errors_idx],\n",
    "    'Pred_Label': [y_pred_labels[i] for i in errors_idx],\n",
    "    'Confiance': [y_pred_proba[i][0] for i in errors_idx]\n",
    "})\n",
    "\n",
    "print(\"\\nüìã Exemples d'erreurs:\")\n",
    "print(errors_df.head(10))\n",
    "\n",
    "# Visualiser quelques erreurs\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(errors_idx[:10]):\n",
    "    img_path = os.path.join(WORK_DIR, 'test', filenames[idx])\n",
    "    img = plt.imread(img_path)\n",
    "\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(\n",
    "        f\"Vrai: {y_true_labels[idx]}\\n\"\n",
    "        f\"Pred: {y_pred_labels[idx]}\\n\"\n",
    "        f\"Conf: {y_pred_proba[idx][0]:.2f}\",\n",
    "        fontsize=10,\n",
    "        color='red'\n",
    "    )\n",
    "\n",
    "plt.suptitle('Exemples d\\'Erreurs de Classification', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analyse_erreurs.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "code\n",
    "#VSC-aa166b85\n",
    "python\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 21) R√©sum√© Final pour le Rapport\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 20 + \"üìä R√âSUM√â FINAL DU PROJET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüéØ OBJECTIF: D√©tection de Pneumonie par Radiographie Thoracique\")\n",
    "print(f\"\\nüìÅ DONN√âES:\")\n",
    "print(f\"  ‚Ä¢ Dataset: Chest X-Ray Images (Pneumonia)\")\n",
    "print(f\"  ‚Ä¢ Training samples: {train_gen.samples}\")\n",
    "print(f\"  ‚Ä¢ Validation samples: {val_gen.samples}\")\n",
    "print(f\"  ‚Ä¢ Test samples: {test_gen.samples}\")\n",
    "print(f\"  ‚Ä¢ Classes: NORMAL (0), PNEUMONIA (1)\")\n",
    "\n",
    "print(f\"\\nü§ñ MOD√àLES COMPAR√âS:\")\n",
    "print(f\"  1. CNN avec Transfer Learning (MobileNetV2)\")\n",
    "print(f\"     - Param√®tres totaux: {cnn_model.count_params():,}\")\n",
    "print(f\"     - Temps d'entra√Ænement: {total_training_time/60:.2f} min\")\n",
    "print(f\"  2. SVM avec features CNN\")\n",
    "print(f\"     - Temps d'entra√Ænement: {svm_training_time/60:.2f} min\")\n",
    "print(f\"  3. Random Forest avec features CNN\")\n",
    "print(f\"     - Temps d'entra√Ænement: {rf_training_time/60:.2f} min\")\n",
    "\n",
    "print(f\"\\nüèÜ MEILLEUR MOD√àLE: {best_model_name}\")\n",
    "print(f\"\\nüìà PERFORMANCES DU MEILLEUR MOD√àLE (Test Set):\")\n",
    "best_idx = results_df['AUC'].idxmax()\n",
    "print(f\"  ‚Ä¢ Accuracy:    {results_df.loc[best_idx, 'Accuracy']:.4f} ({results_df.loc[best_idx, 'Accuracy']*100:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ AUC:         {results_df.loc[best_idx, 'AUC']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision:   {results_df.loc[best_idx, 'Precision']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:      {results_df.loc[best_idx, 'Recall']:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score:    {results_df.loc[best_idx, 'F1-Score']:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  ANALYSE CLINIQUE:\")\n",
    "print(f\"  ‚Ä¢ Faux Positifs: {len(fp_idx)} (patients sains diagnostiqu√©s malades)\")\n",
    "print(f\"  ‚Ä¢ Faux N√©gatifs: {len(fn_idx)} (patients malades non d√©tect√©s)\")\n",
    "print(f\"  ‚Ä¢ Note: En contexte m√©dical, minimiser les Faux N√©gatifs est CRITIQUE\")\n",
    "\n",
    "print(f\"\\nüí° RECOMMANDATIONS:\")\n",
    "print(f\"  ‚Ä¢ Le mod√®le peut servir d'outil d'aide au diagnostic\")\n",
    "print(f\"  ‚Ä¢ Validation m√©dicale obligatoire avant d√©cision clinique\")\n",
    "print(f\"  ‚Ä¢ Surveillance continue des performances en production\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Projet compl√©t√© le {datetime.now().strftime('%Y-%m-%d √† %H:%M:%S')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "code\n",
    "#VSC-d90555e5\n",
    "python\n",
    "\n",
    "code\n",
    "#VSC-3985f08e\n",
    "python\n",
    "# -------------------------------------------------------------\n",
    "# Export explicite des DataFrames importants vers CSV\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "out_dir = 'notebook_outputs/tables'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "# Noms explicites si pr√©sents\n",
    "to_save = {}\n",
    "if 'results_df' in globals():\n",
    "    to_save['results_df'] = results_df\n",
    "if 'errors_df' in globals():\n",
    "    to_save['errors_df'] = errors_df\n",
    "# Chercher toutes les DataFrame pandas dans l'espace global\n",
    "for name, val in list(globals().items()):\n",
    "    try:\n",
    "        if isinstance(val, pd.DataFrame) and name not in to_save:\n",
    "            to_save[name] = val\n",
    "    except Exception:\n",
    "        pass\n",
    "# Sauvegarder\n",
    "for n, df in to_save.items():\n",
    "    path = os.path.join(out_dir, f'{n}.csv')\n",
    "    try:\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f'Saved {path}')\n",
    "    except Exception as e:\n",
    "        print(f'Could not save {n}: {e}')\n",
    "print('Export termin√©')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
